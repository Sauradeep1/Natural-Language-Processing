{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rating Class Pred.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dn4ezOYu9UcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1t5isKO-JeO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "974978fe-8499-4ab4-ef64-b3edd4cb3741"
      },
      "source": [
        "import nltk\n",
        "import os\n",
        "import gc\n",
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "#pd.set_option('display.max_colwidth',100)\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiAlLfzpbj_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtiw9Ws2-PYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', engine='python')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wHjnNJr-lR7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4efd5d03-c677-4185-ea08-ece575958af0"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "miss= SimpleImputer(strategy='constant', fill_value='') \n",
        "miss.fit(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleImputer(add_indicator=False, copy=True, fill_value='', missing_values=nan,\n",
              "              strategy='constant', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9d6NDlt-pcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "74320094-84d4-45d7-80f9-2f50ec922e41"
      },
      "source": [
        "idata =miss.transform(data)\n",
        "idata"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 767, 33, ..., 'Initmates', 'Intimate', 'Intimates'],\n",
              "       [1, 1080, 34, ..., 'General', 'Dresses', 'Dresses'],\n",
              "       [2, 1077, 60, ..., 'General', 'Dresses', 'Dresses'],\n",
              "       ...,\n",
              "       [23483, 1104, 31, ..., 'General Petite', 'Dresses', 'Dresses'],\n",
              "       [23484, 1084, 28, ..., 'General', 'Dresses', 'Dresses'],\n",
              "       [23485, 1104, 52, ..., 'General Petite', 'Dresses', 'Dresses']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAbg6SdO-tXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "8d02852f-6aaa-4ef7-e442-e8f2a1380789"
      },
      "source": [
        "train=pd.DataFrame(data=idata,    # values\n",
        "              index=data.index,    # 1st column as index\n",
        "            columns=data.columns)  # 1st row as the column names\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>767</td>\n",
              "      <td>33</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Initmates</td>\n",
              "      <td>Intimate</td>\n",
              "      <td>Intimates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1080</td>\n",
              "      <td>34</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1077</td>\n",
              "      <td>60</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>General</td>\n",
              "      <td>Dresses</td>\n",
              "      <td>Dresses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1049</td>\n",
              "      <td>50</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>General Petite</td>\n",
              "      <td>Bottoms</td>\n",
              "      <td>Pants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>847</td>\n",
              "      <td>47</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Blouses</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0 Clothing ID Age  ...   Division Name Department Name Class Name\n",
              "0  0          767         33  ...  Initmates       Intimate        Intimates\n",
              "1  1          1080        34  ...  General         Dresses         Dresses  \n",
              "2  2          1077        60  ...  General         Dresses         Dresses  \n",
              "3  3          1049        50  ...  General Petite  Bottoms         Pants    \n",
              "4  4          847         47  ...  General         Tops            Blouses  \n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHOPcPf1-x6Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "895e756e-1b77-46c1-8e30-0a4b2b908276"
      },
      "source": [
        "train.drop(['Clothing ID','Age'], axis =1, inplace=True)\n",
        "train.drop(train.loc[:,'Division Name':'Class Name'], axis=1, inplace=True)\n",
        "train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0                    Title  ... Recommended IND Positive Feedback Count\n",
              "0  0                                   ...  1               0                     \n",
              "1  1                                   ...  1               4                     \n",
              "2  2          Some major design flaws  ...  0               0                     \n",
              "3  3          My favorite buy!         ...  1               0                     \n",
              "4  4          Flattering shirt         ...  1               6                     \n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftb0xcTg_EaO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f004a0d9-a15a-44b6-d551-d54bbf6d61a4"
      },
      "source": [
        "gc.collect()#Forces an immediate garbage collection of all generations to release unreferenced memory"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQIWcda6_Xv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "efdc6ce6-32b5-448a-ce9d-debcefe6f8e4"
      },
      "source": [
        "df_train=train.copy()\n",
        "df_train.shape\n",
        "df_train.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           All\n",
              "0  0          ...   Absolutely wonderful - silky and sexy and comfortable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "1  1          ...   Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.                                                                                                                                                                                                                            \n",
              "2  2          ...  Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n",
              "3  3          ...  My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "4  4          ...  Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!                                                                                                                                                                                                                                                                                                                           \n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yePiwSMGBDWh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "outputId": "805340f9-9d4d-4618-a33f-42d52d8ba96f"
      },
      "source": [
        "df_train['All'] = df_train[['Title','Review Text' ]].apply(lambda x: ' '.join(x), axis=1)\n",
        "df_train.head(7)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Not for the very petite</td>\n",
              "      <td>I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Not for the very petite I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Cagrcoal shimmer fun</td>\n",
              "      <td>I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up). i went with teh darkler color only because i am so pale :-) hte color is really gorgeous, and turns out it mathced everythiing i was trying on with it prefectly. it is a little baggy on me and hte xs is hte msallet size (bummer, no petite). i decided to jkeep it though, because as i said, it matvehd everything. my ejans, pants, and the 3 skirts i waas trying on (of which i ]kept all ) oops.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cagrcoal shimmer fun I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up). i went with teh darkler color only because i am so pale :-) hte color is really gorgeous, and turns out it mathced everythiing i was trying on with it prefectly. it is a little baggy on me and hte xs is hte msallet size (bummer, no petite). i decided to jkeep it though, because as i said, it matvehd everything. my ejans, pants, and the 3 skirts i waas trying on (of which i ]kept all ) oops.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           All\n",
              "0  0          ...   Absolutely wonderful - silky and sexy and comfortable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
              "1  1          ...   Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.                                                                                                                                                                                                                            \n",
              "2  2          ...  Some major design flaws I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c\n",
              "3  3          ...  My favorite buy! I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!                                                                                                                                                                                                                                                                                                                                                                                               \n",
              "4  4          ...  Flattering shirt This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!                                                                                                                                                                                                                                                                                                                           \n",
              "5  5          ...  Not for the very petite I love tracy reese dresses, but this one is not for the very petite. i am just under 5 feet tall and usually wear a 0p in this brand. this dress was very pretty out of the package but its a lot of dress. the skirt is long and very full so it overwhelmed my small frame. not a stranger to alterations, shortening and narrowing the skirt would take away from the embellishment of the garment. i love the color and the idea of the style but it just did not work on me. i returned this dress.            \n",
              "6  6          ...  Cagrcoal shimmer fun I aded this in my basket at hte last mintue to see what it would look like in person. (store pick up). i went with teh darkler color only because i am so pale :-) hte color is really gorgeous, and turns out it mathced everythiing i was trying on with it prefectly. it is a little baggy on me and hte xs is hte msallet size (bummer, no petite). i decided to jkeep it though, because as i said, it matvehd everything. my ejans, pants, and the 3 skirts i waas trying on (of which i ]kept all ) oops.       \n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdfR7gCt_x46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
        "stemmer=SnowballStemmer('english')\n",
        "lemma=WordNetLemmatizer()\n",
        "from string import punctuation\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZEi4UYL_1hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def clean_review(review_col):\n",
        "     review_corpus=[]\n",
        "     for i in range(0,len(review_col)):\n",
        "        review=str(review_col[i])\n",
        "        review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        #review=[stemmer.stem(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "        review=' '.join(review)\n",
        "        review_corpus.append(review)\n",
        "     return review_corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4SB0Xg__6OR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "36030e90-d533-4797-c6c5-373b016ecc4d"
      },
      "source": [
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAoDgBT6Bj3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "0bf1cab3-cd16-4bf6-a14f-1cff465ec407"
      },
      "source": [
        "df_train['All']=clean_review(df_train['All'].values)\n",
        "df_train.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "      <th>All</th>\n",
              "      <th>Rating_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>Absolutely wonderful - silky and sexy and comfortable</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>absolutely wonderful silky and sexy and comfortable</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happened to find it in a store, and i'm glad i did bc i never would have ordered it online bc it's petite.  i bought a petite and am 5'8\".  i love the length on me- hits just a little below the knee.  would definitely be a true midi on someone who is truly petite.</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>love this dress it s sooo pretty i happened to find it in a store and i m glad i did bc i never would have ordered it online bc it s petite i bought a petite and am i love the length on me hit just a little below the knee would definitely be a true midi on someone who is truly petite</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Some major design flaws</td>\n",
              "      <td>I had such high hopes for this dress and really wanted it to work for me. i initially ordered the petite small (my usual size) but i found this to be outrageously small. so small in fact that i could not zip it up! i reordered it in petite medium, which was just ok. overall, the top half was comfortable and fit nicely, but the bottom half had a very tight under layer and several somewhat cheap (net) over layers. imo, a major design flaw was the net over layer sewn directly into the zipper - it c</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>some major design flaw i had such high hope for this dress and really wanted it to work for me i initially ordered the petite small my usual size but i found this to be outrageously small so small in fact that i could not zip it up i reordered it in petite medium which wa just ok overall the top half wa comfortable and fit nicely but the bottom half had a very tight under layer and several somewhat cheap net over layer imo a major design flaw wa the net over layer sewn directly into the zipper it c</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>My favorite buy!</td>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, flirty, and fabulous! every time i wear it, i get nothing but great compliments!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>my favorite buy i love love love this jumpsuit it s fun flirty and fabulous every time i wear it i get nothing but great compliment</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Flattering shirt</td>\n",
              "      <td>This shirt is very flattering to all due to the adjustable front tie. it is the perfect length to wear with leggings and it is sleeveless so it pairs well with any cardigan. love this shirt!!!</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>flattering shirt this shirt is very flattering to all due to the adjustable front tie it is the perfect length to wear with legging and it is sleeveless so it pair well with any cardigan love this shirt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Unnamed: 0  ... Rating_Class\n",
              "0  0          ...  1          \n",
              "1  1          ...  1          \n",
              "2  2          ...  0          \n",
              "3  3          ...  1          \n",
              "4  4          ...  1          \n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S14UhF0QAY1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a20a9d50-82d1-4544-f766-edcdb739961e"
      },
      "source": [
        "df_train['Rating_Class']=np.where(df_train['Rating']>3,1,0)\n",
        "train_text=df_train.All.values\n",
        "target=df_train.Rating_Class.values\n",
        "y=to_categorical(target)\n",
        "print(train_text.shape,target.shape,y.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23486,) (23486,) (23486, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPggnN93EQxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cef089a2-201e-4b98-9ebe-a3962f6cbfad"
      },
      "source": [
        "print(np.unique(y))\n",
        "y.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23486, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ7VkMjLEVuB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d177c9ab-bfd5-4857-ee5f-97a60c686f4a"
      },
      "source": [
        "#train test split\n",
        "X_train_text,X_val_text,y_train,y_val=train_test_split(train_text,y,test_size=0.2,stratify=y,random_state=123)\n",
        "print(X_train_text.shape,y_train.shape)\n",
        "print(X_val_text.shape,y_val.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18788,) (18788, 2)\n",
            "(4698,) (4698, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGVVdlDeEceI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0aa9398e-d7d5-40dd-cacb-c64d3d346a74"
      },
      "source": [
        "#Finding number of unique words in train set\n",
        "all_words=' '.join(X_train_text)\n",
        "all_words=word_tokenize(all_words)\n",
        "dist=FreqDist(all_words)\n",
        "num_unique_word=len(dist)\n",
        "num_unique_word"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIIb4VhzXNYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AAll_words=' '.join(train_text)\n",
        "all_words=word_tokenize(AAll_words)\n",
        "\n",
        "numb_unique_word=len(dist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4VrL-HKXrKi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee6b6ef9-599c-4866-df4c-44f0e765737e"
      },
      "source": [
        "numb_unique_word\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11614"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GD7psHqEge5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e91930e4-a4c8-4c39-b070-699df35394c7"
      },
      "source": [
        "#Finding max length of a review in train set\n",
        "r_len=[]\n",
        "for text in X_train_text:\n",
        "    word=word_tokenize(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_REVIEW_LEN=np.max(r_len)\n",
        "MAX_REVIEW_LEN"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezt1SPV0El2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = num_unique_word\n",
        "max_words = MAX_REVIEW_LEN#max length of a review in train set\n",
        "batch_size = 128\n",
        "epochs = 3\n",
        "num_classes=2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbuboO8eEsN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenize Text\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(X_train_text))\n",
        "X_train = tokenizer.texts_to_sequences(X_train_text)\n",
        "X_val = tokenizer.texts_to_sequences(X_val_text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiAxnVUxFj8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fecf0bc-165f-4c93-b8de-1bf99bfbc67d"
      },
      "source": [
        "#sequence padding\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "print(X_train.shape,X_val.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18788, 123) (4698, 123)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj0egvbVFvs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##############################################Glove word embedding- PRE TRAINED\n",
        "def get_coefs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "def get_embed_mat(EMBEDDING_FILE, max_features,embed_dim):\n",
        "    # word vectors\n",
        "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))#splitting on space\n",
        "    print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "    # embedding matrix\n",
        "    word_index = tokenizer.word_index\n",
        "    num_words = min(max_features, len(word_index) + 1)#max feature is num of unique words\n",
        "    print('after stacking')\n",
        "\n",
        "    embedding_matrix = np.random.normal(0, 1, \n",
        "                                        (num_words, embed_dim))# embedding dimension is 100d - the one we selected\n",
        "    for word, i in word_index.items():\n",
        "        if i >= max_features:\n",
        "            continue\n",
        "        embedding_vector = embeddings_index.get(word)# get value from embeddings_index when key is passed\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    max_features = embedding_matrix.shape[0]\n",
        "    \n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SA5_yYAF10E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c9662e68-238f-4fa8-ddad-00bb3dfe966a"
      },
      "source": [
        "# embedding matrix\n",
        "EMBEDDING_FILE = 'glove.6B.100d.txt'\n",
        "embed_dim = 100             #word vector dim\n",
        "embedding_matrix = get_embed_mat(EMBEDDING_FILE,max_features,embed_dim)\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 246321 word vectors.\n",
            "after stacking\n",
            "(11614, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz2ZFw-FF6g6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "e9993bf5-b63c-41ea-92b4-0748450ba701"
      },
      "source": [
        "model5 = Sequential()\n",
        "model5.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))#embedding_matrix ->pretrained glove\n",
        "model5.add(SpatialDropout1D(0.25))\n",
        "model5.add(Bidirectional(LSTM(128,return_sequences=True)))\n",
        "model5.add(Bidirectional(LSTM(64,return_sequences=False)))\n",
        "model5.add(Dropout(0.5))\n",
        "model5.add(Dense(num_classes, activation='softmax'))\n",
        "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model5.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 123, 100)          1161400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 123, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 123, 256)          234496    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               164352    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,560,506\n",
            "Trainable params: 1,560,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW6Z_EV-GOvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "63e6f577-4180-4ac3-bae3-e3ceab341399"
      },
      "source": [
        "%%time\n",
        "history5=model5.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=4, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/4\n",
            "18788/18788 [==============================] - 112s 6ms/step - loss: 0.4851 - acc: 0.7835 - val_loss: 0.3885 - val_acc: 0.8242\n",
            "Epoch 2/4\n",
            "18788/18788 [==============================] - 108s 6ms/step - loss: 0.3478 - acc: 0.8526 - val_loss: 0.2836 - val_acc: 0.8840\n",
            "Epoch 3/4\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.2875 - acc: 0.8791 - val_loss: 0.3105 - val_acc: 0.8799\n",
            "Epoch 4/4\n",
            "18788/18788 [==============================] - 110s 6ms/step - loss: 0.2567 - acc: 0.8956 - val_loss: 0.2615 - val_acc: 0.9000\n",
            "CPU times: user 10min 47s, sys: 1min 8s, total: 11min 56s\n",
            "Wall time: 7min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyKGs3TOImCP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "3b511c27-bb2e-43a7-979c-ab19db04b46c"
      },
      "source": [
        "history5=model5.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=40, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/40\n",
            "18788/18788 [==============================] - 110s 6ms/step - loss: 0.2232 - acc: 0.9086 - val_loss: 0.2375 - val_acc: 0.9063\n",
            "Epoch 2/40\n",
            "18788/18788 [==============================] - 108s 6ms/step - loss: 0.2092 - acc: 0.9180 - val_loss: 0.2246 - val_acc: 0.9057\n",
            "Epoch 3/40\n",
            "18788/18788 [==============================] - 108s 6ms/step - loss: 0.1903 - acc: 0.9272 - val_loss: 0.2343 - val_acc: 0.9076\n",
            "Epoch 4/40\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.1747 - acc: 0.9318 - val_loss: 0.2347 - val_acc: 0.9115\n",
            "Epoch 5/40\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.1636 - acc: 0.9393 - val_loss: 0.2453 - val_acc: 0.9066\n",
            "Epoch 6/40\n",
            "18788/18788 [==============================] - 106s 6ms/step - loss: 0.1482 - acc: 0.9435 - val_loss: 0.2469 - val_acc: 0.9072\n",
            "Epoch 7/40\n",
            " 8448/18788 [============>.................] - ETA: 52s - loss: 0.1322 - acc: 0.9524"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e59fa3cc286b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI61LlshUeSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yLI61gELlh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCnnzXNXLhfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9bd9d3e0-9abf-4d00-f6f5-f0e05d3690c7"
      },
      "source": [
        "model6 = Sequential()\n",
        "model6.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
        "model6.add(SpatialDropout1D(0.25))\n",
        "model6.add(Bidirectional(GRU(128,return_sequences=True)))\n",
        "model6.add(Bidirectional(GRU(64,return_sequences=False)))\n",
        "model6.add(Dropout(0.5))\n",
        "model6.add(Dense(num_classes, activation='softmax'))\n",
        "model6.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model6.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 123, 100)          1161400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 123, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 123, 256)          175872    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 128)               123264    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,460,794\n",
            "Trainable params: 1,460,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn5rnPjLLmdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "798967e5-6446-43c2-e3ef-d50d0806561a"
      },
      "source": [
        "history5=model6.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/10\n",
            "18788/18788 [==============================] - 90s 5ms/step - loss: 0.5135 - acc: 0.7726 - val_loss: 0.4152 - val_acc: 0.8195\n",
            "Epoch 2/10\n",
            "18788/18788 [==============================] - 86s 5ms/step - loss: 0.3282 - acc: 0.8557 - val_loss: 0.2591 - val_acc: 0.8891\n",
            "Epoch 3/10\n",
            "18788/18788 [==============================] - 86s 5ms/step - loss: 0.2545 - acc: 0.8968 - val_loss: 0.2258 - val_acc: 0.9085\n",
            "Epoch 4/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.2336 - acc: 0.9051 - val_loss: 0.2380 - val_acc: 0.8995\n",
            "Epoch 5/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.2032 - acc: 0.9207 - val_loss: 0.2232 - val_acc: 0.9138\n",
            "Epoch 6/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.1903 - acc: 0.9269 - val_loss: 0.2252 - val_acc: 0.9104\n",
            "Epoch 7/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.1755 - acc: 0.9327 - val_loss: 0.2218 - val_acc: 0.9115\n",
            "Epoch 8/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.1622 - acc: 0.9399 - val_loss: 0.2334 - val_acc: 0.9102\n",
            "Epoch 9/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.1448 - acc: 0.9470 - val_loss: 0.2377 - val_acc: 0.9072\n",
            "Epoch 10/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.1333 - acc: 0.9514 - val_loss: 0.2523 - val_acc: 0.9087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpdu1V-hTnDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "dc286424-1dff-424d-99e3-9d968f24cb5d"
      },
      "source": [
        "history5=model5.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/10\n",
            "18788/18788 [==============================] - 106s 6ms/step - loss: 0.1341 - acc: 0.9508 - val_loss: 0.2623 - val_acc: 0.9063\n",
            "Epoch 2/10\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.1213 - acc: 0.9561 - val_loss: 0.2780 - val_acc: 0.9061\n",
            "Epoch 3/10\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.1126 - acc: 0.9598 - val_loss: 0.2950 - val_acc: 0.9044\n",
            "Epoch 4/10\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.1029 - acc: 0.9619 - val_loss: 0.2955 - val_acc: 0.9046\n",
            "Epoch 5/10\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.0980 - acc: 0.9640 - val_loss: 0.2805 - val_acc: 0.8957\n",
            "Epoch 6/10\n",
            "18788/18788 [==============================] - 108s 6ms/step - loss: 0.0877 - acc: 0.9678 - val_loss: 0.3317 - val_acc: 0.9010\n",
            "Epoch 7/10\n",
            "18788/18788 [==============================] - 107s 6ms/step - loss: 0.0821 - acc: 0.9696 - val_loss: 0.3510 - val_acc: 0.8946\n",
            "Epoch 8/10\n",
            " 2816/18788 [===>..........................] - ETA: 1:23 - loss: 0.0744 - acc: 0.9744"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-eb9b3f60266d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m1T_aZ3Yt2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nccF7YnZp9G",
        "colab_type": "text"
      },
      "source": [
        "Spatial Dropout- This version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG8vHz-gUjC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "be51fb9c-8f41-42f7-b004-5067635b49ad"
      },
      "source": [
        "\n",
        "model7 = Sequential()\n",
        "model7.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
        "model7.add(SpatialDropout1D(0.35))\n",
        "model7.add(Bidirectional(GRU(128,return_sequences=True)))\n",
        "model7.add(Bidirectional(GRU(64,return_sequences=False)))\n",
        "model7.add(Dropout(0.5))\n",
        "model7.add(Dense(num_classes, activation='softmax'))\n",
        "model7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model7.summary()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 123, 100)          1161400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_3 (Spatial (None, 123, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 123, 256)          175872    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 128)               123264    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,460,794\n",
            "Trainable params: 1,460,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXVfaNaWbIWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uToadiVhYu1a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "c1da3eeb-0df7-48eb-be72-e5423ba0ae72"
      },
      "source": [
        "history5=model7.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/10\n",
            "18788/18788 [==============================] - 90s 5ms/step - loss: 0.5142 - acc: 0.7731 - val_loss: 0.3420 - val_acc: 0.8438\n",
            "Epoch 2/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.3408 - acc: 0.8512 - val_loss: 0.2641 - val_acc: 0.8908\n",
            "Epoch 3/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.2718 - acc: 0.8862 - val_loss: 0.2354 - val_acc: 0.9049\n",
            "Epoch 4/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.2339 - acc: 0.9045 - val_loss: 0.2228 - val_acc: 0.9091\n",
            "Epoch 5/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.2214 - acc: 0.9106 - val_loss: 0.2240 - val_acc: 0.9093\n",
            "Epoch 6/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.1996 - acc: 0.9202 - val_loss: 0.2268 - val_acc: 0.9070\n",
            "Epoch 7/10\n",
            " 8192/18788 [============>.................] - ETA: 45s - loss: 0.1827 - acc: 0.9288"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a7c99a8d287b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFhU9VmDcJby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9d9oVyobJ_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "f43c9b65-d67a-4710-bda5-c7bfba221331"
      },
      "source": [
        "model8 = Sequential()\n",
        "model8.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
        "model8.add(SpatialDropout1D(0.35))\n",
        "model8.add(Bidirectional(GRU(128,return_sequences=True)))\n",
        "model8.add(Bidirectional(GRU(64,return_sequences=False)))\n",
        "model8.add(Dropout(0.5))\n",
        "model8.add(Dense(num_classes, activation='softmax'))\n",
        "model8.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# simple early stopping\n",
        "\n",
        "\n",
        "model8.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 123, 100)          1161400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_7 (Spatial (None, 123, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 123, 256)          175872    \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 128)               123264    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,460,794\n",
            "Trainable params: 1,460,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbWu6Gv4pAyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB6J3JM2cKh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "164e15c9-a928-4d14-a380-c58a398318ad"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "history5=model8.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1, callbacks=[es, mc])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/10\n",
            "18788/18788 [==============================] - 94s 5ms/step - loss: 0.5127 - acc: 0.7698 - val_loss: 0.3486 - val_acc: 0.8453\n",
            "Epoch 2/10\n",
            "18788/18788 [==============================] - 90s 5ms/step - loss: 0.3380 - acc: 0.8542 - val_loss: 0.2561 - val_acc: 0.8900\n",
            "Epoch 3/10\n",
            "18788/18788 [==============================] - 89s 5ms/step - loss: 0.2655 - acc: 0.8915 - val_loss: 0.2479 - val_acc: 0.9004\n",
            "Epoch 4/10\n",
            "18788/18788 [==============================] - 90s 5ms/step - loss: 0.2365 - acc: 0.9034 - val_loss: 0.2360 - val_acc: 0.9066\n",
            "Epoch 5/10\n",
            "18788/18788 [==============================] - 90s 5ms/step - loss: 0.2204 - acc: 0.9129 - val_loss: 0.2239 - val_acc: 0.9095\n",
            "Epoch 6/10\n",
            "18788/18788 [==============================] - 91s 5ms/step - loss: 0.2042 - acc: 0.9216 - val_loss: 0.2349 - val_acc: 0.9087\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHLUiQNsjpgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "54ec431f-7b0b-495c-9d38-e977b9a99045"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history5.history['loss'], label='train')\n",
        "pyplot.plot(history5.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "# training was stopped at the point when validation loss began to plateau for the first time."
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGGN8nAW9Mcb4OAt6Y4zxcf8/SVkoHyVyOgEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8Nj1YmqkGhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "48350275-cebf-4301-f43a-dbcfc7c051d5"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "history8=model8.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1, callbacks=[es, mc])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/10\n",
            "18788/18788 [==============================] - 89s 5ms/step - loss: 0.1925 - acc: 0.9242 - val_loss: 0.2221 - val_acc: 0.9110\n",
            "Epoch 2/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.1832 - acc: 0.9293 - val_loss: 0.2251 - val_acc: 0.9115\n",
            "Epoch 3/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.1704 - acc: 0.9352 - val_loss: 0.2349 - val_acc: 0.9138\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMTTQ53gnarO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f9fc5e63-1305-4eca-c32c-377450714afc"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "history8=model8.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1, callbacks=[es, mc])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/10\n",
            "18788/18788 [==============================] - 89s 5ms/step - loss: 0.1630 - acc: 0.9362 - val_loss: 0.2346 - val_acc: 0.9108\n",
            "Epoch 2/10\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.1498 - acc: 0.9436 - val_loss: 0.2346 - val_acc: 0.9097\n",
            "Epoch 3/10\n",
            "18788/18788 [==============================] - 86s 5ms/step - loss: 0.1425 - acc: 0.9476 - val_loss: 0.2466 - val_acc: 0.9070\n",
            "Epoch 4/10\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.1303 - acc: 0.9513 - val_loss: 0.2550 - val_acc: 0.9087\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TTULnbnqTWj",
        "colab_type": "text"
      },
      "source": [
        "Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXRJxVYIpCXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "102de6e6-a5bb-4feb-bd57-621ea60ba913"
      },
      "source": [
        "model9 = Sequential()\n",
        "model9.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
        "model9.add(SpatialDropout1D(0.35))\n",
        "model9.add(Bidirectional(GRU(128,return_sequences=True)))\n",
        "model9.add(Bidirectional(GRU(128,return_sequences=True)))\n",
        "model9.add(Bidirectional(GRU(64,return_sequences=False)))\n",
        "model9.add(Dropout(0.5))\n",
        "model9.add(Dense(num_classes, activation='softmax'))\n",
        "model9.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model9.summary()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 123, 100)          1161400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_8 (Spatial (None, 123, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 123, 256)          175872    \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 123, 256)          295680    \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 128)               123264    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,756,474\n",
            "Trainable params: 1,756,474\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVNhKd8Gp7dP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2bf0fc90-8378-4f34-a445-d8caba3a9de3"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "history9=model9.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1, callbacks=[es, mc])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/10\n",
            "18788/18788 [==============================] - 136s 7ms/step - loss: 0.5334 - acc: 0.7646 - val_loss: 0.4115 - val_acc: 0.8135\n",
            "Epoch 2/10\n",
            "18788/18788 [==============================] - 127s 7ms/step - loss: 0.3546 - acc: 0.8450 - val_loss: 0.2553 - val_acc: 0.8963\n",
            "Epoch 3/10\n",
            "18788/18788 [==============================] - 126s 7ms/step - loss: 0.2761 - acc: 0.8832 - val_loss: 0.2374 - val_acc: 0.9042\n",
            "Epoch 4/10\n",
            "18788/18788 [==============================] - 125s 7ms/step - loss: 0.2397 - acc: 0.9038 - val_loss: 0.2269 - val_acc: 0.9055\n",
            "Epoch 5/10\n",
            "18788/18788 [==============================] - 125s 7ms/step - loss: 0.2186 - acc: 0.9126 - val_loss: 0.2246 - val_acc: 0.9093\n",
            "Epoch 6/10\n",
            "18788/18788 [==============================] - 125s 7ms/step - loss: 0.2075 - acc: 0.9178 - val_loss: 0.2244 - val_acc: 0.9100\n",
            "Epoch 7/10\n",
            "18788/18788 [==============================] - 125s 7ms/step - loss: 0.1884 - acc: 0.9251 - val_loss: 0.2274 - val_acc: 0.9125\n",
            "Epoch 8/10\n",
            "18788/18788 [==============================] - 125s 7ms/step - loss: 0.1747 - acc: 0.9324 - val_loss: 0.2391 - val_acc: 0.9093\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqKjmkywN3CZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e314ba17-1fb8-47d7-f299-86c6cedab732"
      },
      "source": [
        "model10 = Sequential()\n",
        "model10.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
        "model10.add(SpatialDropout1D(0.25))\n",
        "model10.add(Bidirectional(GRU(64,return_sequences=True)))\n",
        "model10.add(Bidirectional(GRU(32,return_sequences=False)))\n",
        "model10.add(Dropout(0.5))\n",
        "model10.add(Dense(num_classes, activation='softmax'))\n",
        "model10.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model10.summary()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_9 (Embedding)      (None, 123, 100)          1161400   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_9 (Spatial (None, 123, 100)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_18 (Bidirectio (None, 123, 128)          63360     \n",
            "_________________________________________________________________\n",
            "bidirectional_19 (Bidirectio (None, 64)                30912     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 1,255,802\n",
            "Trainable params: 1,255,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2A5JmPHQxnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SCpJ9mRODpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "43ed3789-1a5b-45b0-8626-f28b167d3cdd"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "history10=model10.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=20, batch_size=batch_size, verbose=1, callbacks=[es, mc])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 18788 samples, validate on 4698 samples\n",
            "Epoch 1/20\n",
            "18788/18788 [==============================] - 96s 5ms/step - loss: 0.5224 - acc: 0.7699 - val_loss: 0.3926 - val_acc: 0.8203\n",
            "Epoch 2/20\n",
            "18788/18788 [==============================] - 88s 5ms/step - loss: 0.3418 - acc: 0.8500 - val_loss: 0.2547 - val_acc: 0.8938\n",
            "Epoch 3/20\n",
            "18788/18788 [==============================] - 87s 5ms/step - loss: 0.2666 - acc: 0.8901 - val_loss: 0.2326 - val_acc: 0.9029\n",
            "Epoch 4/20\n",
            "18788/18788 [==============================] - 86s 5ms/step - loss: 0.2317 - acc: 0.9069 - val_loss: 0.2236 - val_acc: 0.9076\n",
            "Epoch 5/20\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.2123 - acc: 0.9143 - val_loss: 0.2263 - val_acc: 0.9093\n",
            "Epoch 6/20\n",
            "18788/18788 [==============================] - 85s 5ms/step - loss: 0.1942 - acc: 0.9256 - val_loss: 0.2237 - val_acc: 0.9117\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ3kO87oQyuF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b72eea23-9a09-4173-b09e-26d977b37ca5"
      },
      "source": [
        "pyplot.plot(history10.history['loss'], label='train')\n",
        "pyplot.plot(history10.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhU9dn/8fc9WcnKkkA2MGEP+xIR\nFRWrIougVWvVH62tVrRK1dpaofp0catdHh+11Vq0WLtYq6gtu0AFBQUkKHsImyDZSAgCCYSs9++P\nGcIEAwkwyZnM3K/rypXMWSafseVzTs7yPaKqGGOMCVwupwMYY4xpWVb0xhgT4KzojTEmwFnRG2NM\ngLOiN8aYABfqdICTJSQkaHp6utMxjDGmTVm7du1+VU1sbJ7fFX16ejrZ2dlOxzDGmDZFRPacap4d\nujHGmABnRW+MMQHOit4YYwKc3x2jN8aYs1FdXU1eXh7Hjh1zOkqLioyMJC0tjbCwsGavY0VvjAkI\neXl5xMbGkp6ejog4HadFqCqlpaXk5eWRkZHR7PXs0I0xJiAcO3aMTp06BWzJA4gInTp1OuO/Wqzo\njTEBI5BL/riz+YwBU/TllTX8ZuFWdu8/4nQUY4zxKwFT9Ecra/jLx7v59cKtTkcxxgShgwcP8uKL\nL57xeuPHj+fgwYMtkOiEgCn6znGR3HVpDxZsKmLN7gNOxzHGBJlTFX1NTc1p15s/fz7t27dvqVhA\nABU9wJ2XZtAlLoIn5uVQV2dPzjLGtJ5p06axc+dOhgwZwvnnn88ll1zCpEmT6NevHwDXXXcdw4cP\np3///syYMaN+vfT0dPbv38/u3bvJzMzkzjvvpH///owZM4aKigqfZAuoyyujwkN56Oq+/Pit9czZ\nUMC1Q1KdjmSMccAv52xmS8Fhn75nv5Q4fj6x/ynnP/3002zatIl169axbNkyJkyYwKZNm+ovg5w5\ncyYdO3akoqKC888/nxtuuIFOnTo1eI/t27fzz3/+k5dffpmbbrqJt99+m8mTJ59z9oDaowe4fmgq\n/VPi+M3CXI5V1zodxxgTpEaMGNHgWvfnn3+ewYMHM3LkSPbu3cv27du/sk5GRgZDhgwBYPjw4eze\nvdsnWQJqjx7A5RIemZDJrS+vZuZHn3PP6J5ORzLGtLLT7Xm3lujo6Pqfly1bxpIlS1i5ciVRUVGM\nHj260WvhIyIi6n8OCQnx2aGbgNujB7ioRwJXZnbmxaU72V9e6XQcY0wQiI2NpaysrNF5hw4dokOH\nDkRFRbF161ZWrVrVqtkCsugBpo/P5Fh1Lf+3eJvTUYwxQaBTp05cfPHFDBgwgIceeqjBvLFjx1JT\nU0NmZibTpk1j5MiRrZpNVP3r6pSsrCz11YNHfv6fTfxt1R7ee+BSenWJ9cl7GmP8U05ODpmZmU7H\naBWNfVYRWauqWY0tH7B79AD3X9mb6IhQnpqf43QUY4xxTEAXfcfocKZe3pOluSWs2L7f6TjGGOOI\nZhW9iIwVkVwR2SEi0xqZ/x0RKRGRdZ6v73nNu01Etnu+bvNl+Oa47aJ00jq044l5W6i1m6iMMUGo\nyaIXkRDgBWAc0A+4RUT6NbLov1R1iOfrFc+6HYGfAxcAI4Cfi0gHn6VvhsiwEKaN68vWojJmrd3b\nmr/aGGP8QnP26EcAO1R1l6pWAW8A1zbz/a8GFqvqAVX9ElgMjD27qGdvwsBkhnVrz+8WbeNI5enH\nnTDGmEDTnKJPBbx3hfM80052g4hsEJFZItL1TNYVkSkiki0i2SUlJc2M3nwiwiMT+lFSVsmfPtzl\n8/c3xhh/5quTsXOAdFUdhHuv/bUzWVlVZ6hqlqpmJSYm+ihSQ8PP68CEQcnM+HAnRYcC+5mSxpjW\nd7bDFAM8++yzHD161MeJTmhO0ecDXb1ep3mm1VPVUlU9fgvqK8Dw5q7bmqaN7UtdHfz2vVynIhhj\nApQ/F31zxrpZA/QSkQzcJX0zcKv3AiKSrKqFnpeTgOMXrr8HPOV1AnYMMP2cU5+lrh2j+O7F6cxY\nvovvXpzOgNR4p6IYYwKM9zDFV111FZ07d+bNN9+ksrKSr3/96/zyl7/kyJEj3HTTTeTl5VFbW8v/\n/M//sG/fPgoKCrj88stJSEhg6dKlPs/WZNGrao2ITMVd2iHATFXdLCKPAdmqOhu4T0QmATXAAeA7\nnnUPiMjjuDcWAI+pqqNPBbnn8p68mb2XJ+fl8PqdFwTFMyaNCToLpkHRRt++Z9JAGPf0KWd7D1O8\naNEiZs2axSeffIKqMmnSJD788ENKSkpISUlh3rx5gHsMnPj4eJ555hmWLl1KQkKCbzN7NOsYvarO\nV9XeqtpDVZ/0TPuZp+RR1emq2l9VB6vq5aq61Wvdmara0/P1aot8ijMQ3y6MB67szcpdpfw3p9jp\nOMaYALRo0SIWLVrE0KFDGTZsGFu3bmX79u0MHDiQxYsX8/DDD7N8+XLi41vnqELADVPcHLde0I3X\nVu7mqfk5XNYnkbCQgL5B2Jjgc5o979agqkyfPp277rrrK/M+/fRT5s+fz6OPPsoVV1zBz372sxbP\nE5QNFxbi4qfjMtm1/wivr/7C6TjGmADgPUzx1VdfzcyZMykvLwcgPz+f4uJiCgoKiIqKYvLkyTz0\n0EN8+umnX1m3JQTlHj3AFZmdubB7J55dso3rhqYS3y7M6UjGmDbMe5jicePGceutt3LhhRcCEBMT\nw9///nd27NjBQw89hMvlIiwsjD/+8Y8ATJkyhbFjx5KSktIiJ2MDepjipmzKP8TEP6xgyiXdmT4+\nOIY3NSZQ2TDFQTpMcVMGpMZzw7A0Xv1oN3sPtNw1rMYY46SgLnqAH4/pQ4hLeHrh1qYXNsaYNijo\niz4pPpI7L+3OvA2FrN3zpdNxjDHnwN8ORbeEs/mMQV/0AHdd2p3E2AiemLclKP6PYkwgioyMpLS0\nNKD/DasqpaWlREZGntF6QXvVjbfoiFB+PKY3D7+9kXkbC7lmUIrTkYwxZygtLY28vDxaYgRcfxIZ\nGUlaWtoZrWNF73Hj8K68+tFunl6wlSszuxAZFuJ0JGPMGQgLCyMjI8PpGH7JDt14hLiERyf0I+/L\nCl77eLfTcYwxxmes6L2M6pXA5X0S+cPSHRw4UuV0HGOM8Qkr+pP8dHwmR6tqeW7JNqejGGOMT1jR\nn6RXl1huGdGVv6/+gh3F5U7HMcaYc2ZF34gHruxNu7AQnl6Q0/TCxhjj56zoG5EQE8E9l/dgSU4x\nH+/c73QcY4w5J1b0p3D7xRmktm/HE3NzqK0L3BswjDGBz4r+FCLDQvjJ2D5sKTzMO5/mOR3HGGPO\nmhX9aUwanMLgru353aJcjlbVOB3HGGPOihX9aYgI/zMhk32HK3n5w8+djmOMMWfFir4JWekdGTcg\niZc+2Mm+w8ecjmOMMWesWUUvImNFJFdEdojItNMsd4OIqIhkeV6ni0iFiKzzfL3kq+Ctadq4vtTU\n1fG/i3KdjmKMMWesyaIXkRDgBWAc0A+4RUT6NbJcLHA/sPqkWTtVdYjn624fZG5153WK5rYL03lr\nbR5bCg47HccYY85Ic/boRwA7VHWXqlYBbwDXNrLc48CvgYA8vvGDr/Uivl0YT83PCejxro0xgac5\nRZ8K7PV6neeZVk9EhgFdVXVeI+tniMhnIvKBiFzS2C8QkSkiki0i2f46lnR8VBj3fa0XK3bsZ1mu\nf2Y0xpjGnPPJWBFxAc8AP2pkdiHQTVWHAg8Cr4tI3MkLqeoMVc1S1azExMRzjdRiJo88j/ROUTw5\nP4ea2jqn4xhjTLM0p+jzga5er9M8046LBQYAy0RkNzASmC0iWapaqaqlAKq6FtgJ9PZFcCeEh7qY\nPj6THcXl/HPN3qZXMMYYP9Ccol8D9BKRDBEJB24GZh+fqaqHVDVBVdNVNR1YBUxS1WwRSfSczEVE\nugO9gF0+/xStaEy/LozI6Mizi7dRdqza6TjGGNOkJoteVWuAqcB7QA7wpqpuFpHHRGRSE6tfCmwQ\nkXXALOBuVT1wrqGdJCI8OiGT0iNVvLhsp9NxjDGmSeJvV5BkZWVpdna20zGa9MN/rWPexkLe/9Fl\npHWIcjqOMSbIichaVc1qbJ7dGXuWHrq6DwL8ZqHdRGWM8W9W9GcppX077rykO7PXF7Bu70Gn4xhj\nzClZ0Z+Du0f3ICEmgifmbrGbqIwxfsuK/hzERITy4FW9yd7zJQs3FTkdxxhjGmVFf45uykqjT5dY\nfrVgK5U1tU7HMcaYr7CiP0ehIS5+OiGTLw4c5W8r9zgdxxhjvsKK3gcu653Ipb0Tef6/2/nySJXT\ncYwxpgEreh95ZHwm5ZU1PP/+dqejGGNMA1b0PtInKZZvnt+Nv63cw66ScqfjGGNMPSt6H3rwqt5E\nhLp4esFWp6MYY0w9K3ofSoyN4Puje7Boyz5W7Sp1Oo4xxgBW9D53x6juJMdH8uS8HOrq7CYqY4zz\nrOh9rF14CA9d3YeN+Yf497r8plcwxpgWZkXfAq4bksrA1Hh++14uFVV2E5UxxllW9C3A5XKPWV94\n6Bh/XtGmn7NijAkAVvQt5ILunRjTrwt/XLaT4rJjTscxxgQxK/oWNG1cXypr6vi/xXYTlTHGOVb0\nLah7YgzfuvA8/rXmC3KLypyOY4wJUlb0Lez+K3oRExHKk/NznI5ijAlSVvQtrH1UOPdd0YsPt5Xw\nwbYSp+MYY4KQFX0r+NaF59GtYxRPzttCTW2d03GMMUGmWUUvImNFJFdEdojItNMsd4OIqIhkeU2b\n7lkvV0Su9kXotiYiNITp4/qybV85b2bnOR3HGBNkmix6EQkBXgDGAf2AW0SkXyPLxQL3A6u9pvUD\nbgb6A2OBFz3vF3TGDkji/PQOPLM4l/LKGqfjGGOCSHP26EcAO1R1l6pWAW8A1zay3OPArwHvi8av\nBd5Q1UpV/RzY4Xm/oCMiPDKhH/vLq3hp2U6n4xhjgkhzij4V2Ov1Os8zrZ6IDAO6quq8M13Xs/4U\nEckWkeySksA9YTmka3smDU7h5eW7KDhY4XQcY0yQOOeTsSLiAp4BfnS276GqM1Q1S1WzEhMTzzWS\nX/vJ2D4o8Nv3cp2OYowJEs0p+nygq9frNM+042KBAcAyEdkNjARme07INrVu0EnrEMUdozJ497N8\nNuQddDqOMSYINKfo1wC9RCRDRMJxn1ydfXymqh5S1QRVTVfVdGAVMElVsz3L3SwiESKSAfQCPvH5\npzhuy3+g0v/vQL1ndA86RYfzxLwcVG3MemNMy2qy6FW1BpgKvAfkAG+q6mYReUxEJjWx7mbgTWAL\nsBC4V1VbZtze/dvhre/A/Ida5O19KTYyjAeu6s0nnx9g0ZZ9TscxxgQ48bc9yqysLM3Ozj67lZc9\nDct+BV//Ewy+2bfBfKymto6xzy2npraORT+8jPBQu3fNGHP2RGStqmY1Ni+w2uXSh+C8i2Hug7B/\nh9NpTis0xMUj4zPZXXqUv6/a43QcY0wAC6yid4XA9S9DaDjM+i7UVDqd6LRG90lkVM8Enn9/O4eO\nVjsdxxgToAKr6AHiU+G6P0LRBljyC6fTnJaI8NPxmRyqqOb379uY9caYlhF4RQ/QZxxccDesehFy\nFzid5rT6pcTxjeFpvLZyN3tKjzgdxxgTgAKz6AGuegySBsG/74HDBU6nOa0fjelDWIiLpxdsdTqK\nMSYABW7Rh0bAja+6j9O/fSfUtcxVnb7QJS6Suy7twYJNRazZfcDpOMaYABO4RQ+Q0BMm/C/sWQEf\n/s7pNKd156UZdImL4Il5OdTV+dclr8aYti2wix5gyC0w6Gb44GnY/ZHTaU4pKjyUH4/pw/q9B5mz\nwb8PNRlj2pbAL3qACb+DDhnwzp1w1H8PjdwwLI3+KXH8ZmEux6r991CTMaZtCY6ij4iFG2dCeTH8\n517ws7uBj3O5hEcmZJJ/sIKZH33udBxjTIAIjqIHSBkCYx6H3PnwyctOpzmli3okcGVmZ15cupP9\n5f59w5cxpm0InqIH97X1vcfCokegcIPTaU5p2rhMKqpreXbJNqejGGMCQHAVvQhc+yJEdXIPkVBZ\n7nSiRvXsHMPkC7rx+uov2L7P/4ddNsb4t+AqeoDoTnDDK3BgFyz4idNpTun+K3sTHRHKU/NznI5i\njGnjgq/oAdJHuUe6XPcPWP8vp9M0qmN0OFMv78nS3BJWbN/vdBxjTBsWnEUPcOlPoNtFMO9BKN3p\ndJpG3XZROmkd2vHEvC3U2k1UxpizFLxFHxIKN7wMIWF+O6RxZFgID4/ty9aiMmat3et0HGNMGxW8\nRQ8QnwbXvgCF62HJL51O06hrBiUztFt7frdoG0cqa5yOY4xpg4K76AH6ToARd8GqF2Dbe06n+QoR\n4dEJ/Sgpq+RPH+5yOo4xpg2yogfPkMYD4d/f98shjYef14EJg5KZ8eFOig4dczqOMaaNsaIHCIt0\nD2lcfQzemeKXQxpPG9uXujr47Xu5TkcxxrQxzSp6ERkrIrkiskNEpjUy/24R2Sgi60RkhYj080xP\nF5EKz/R1IvKSrz+AzyT0cg9+tns5LH/G6TRf0bVjFN+9OJ13PstjU/4hp+MYY9qQJoteREKAF4Bx\nQD/gluNF7uV1VR2oqkOA3wDeTblTVYd4vu72VfAWMfgWGHgTLHsK9nzsdJqvuOfynrRvF8aT83JQ\nPx2YzRjjf5qzRz8C2KGqu1S1CngDuNZ7AVU97PUyGmibLSQC1zwDHdLdT6XysyGN49uF8cCVvVm5\nq5T/5hQ7HccY00Y0p+hTAe+LuPM80xoQkXtFZCfuPfr7vGZliMhnIvKBiFzS2C8QkSkiki0i2SUl\nJWcQvwXUD2m8D2b/wO+GNL71gm50T4zmqQU5VNfWOR3HGNMG+OxkrKq+oKo9gIeBRz2TC4FuqjoU\neBB4XUTiGll3hqpmqWpWYmKiryKdvZShcNUvYetcWPOK02kaCAtx8dNxmewqOcLrq79wOo4xpg1o\nTtHnA129Xqd5pp3KG8B1AKpaqaqlnp/XAjuB3mcXtZWNvAd6XQ3vPQJFG51O08AVmZ25sHsnnl2y\njUMV1U7HMcb4ueYU/Rqgl4hkiEg4cDMw23sBEenl9XICsN0zPdFzMhcR6Q70AtrGXT8icN2LENUR\n3vouVB1xOlE9EfeTqA5WVPPi0h1OxzHG+Lkmi15Va4CpwHtADvCmqm4WkcdEZJJnsakisllE1uE+\nRHObZ/qlwAbP9FnA3arqX2c4Tyc6Aa6fAaU7YL5/DWk8IDWe64em8epHu/nsiy+djmOM8WPib5fp\nZWVlaXZ2ttMxGnr/SfjwN3D9KzDoG06nqbfv8DGuf/FjisuO8fDYvtwxKgMRcTqWMcYBIrJWVbMa\nm2d3xjbHZQ9Dtwth7g/9akjjLnGRzLtvFKP7dOaJeTnc+ddsDh6tcjqWMcbPWNE3R0io+6lUrhB4\n+w6o8Z8ybR8VzoxvDedn1/Tjg20ljH9uOWv3tJ2jY8aYlmdF31zHhzQu+Az+619DGosIt4/K4O3v\nX0RoiIub/rSKPy7bSZ09rMQYgxX9mcm8Bs6/E1b+AbYtcjrNVwxKa8/c+0Zxdf8u/HrhVr77lzWU\nlvvfA1WMMa3Liv5MjXkCugyAf98NhwudTvMVcZFhvHDrMB6/bgArd5Uy/vnlrNpV6nQsY4yDrOjP\nVP2QxhXwrn8OaSwifGvkebx7z0VEhYdy68ureP6/2+25s8YEKSv6s5HYG8b/Fj7/EFb435DGx/VP\niWfOD0YxcXAKzyzexrdnrqa4zB5cYkywsaI/W0P+Hwz8Biz9FXyxyuk0pxQTEcqz3xzCr28YyNo9\nXzL+uRV8tGO/07GMMa3Iiv5sicCEZ6B9N3j7e343pLE3EeGb53fjP/eOon1UGJP/vJpnFuVSY6Nf\nGhMUrOjPRWSce0jjsiK/HNL4ZH2SYpk99WJuHJbG8+/v4NZXVtszaI0JAlb05yp1GFz5C/eQxtl/\ndjpNk6LCQ/ntNwbzzE2D2ZR/iPHPL2dZrj3ExJhAZkXvCyPvgV5jYOFPoWiT02ma5fphacyeOorO\nsRF859U1PL1gqz3IxJgAZUXvCy4XXPdHaNcBZvnXkMan07NzDP++92JuvaAbL32wk5tnrCL/YIXT\nsYwxPmZF7yvHhzTevx0WPOx0mmaLDAvhqa8P5PlbhpJbVMb455azeMs+p2MZY3zIit6Xul8Gl/wI\nPvsbbJzldJozMmlwCnN/MIquHdtx51+zeXzuFqpq7FCOMYHAit7XRk+HriNhzgNwoG08TOu49IRo\n3v7+RXznonT+vOJzvvHSx+w9cNTpWMaYc2RF72v1Qxq7YJZ/DWncHBGhIfxiUn9emjyMXfuPMP75\n5SzY6H9j+hhjms+KviW07+oZ0vhTeP8xp9OclbEDkpl/3yV0T4zh+//4lJ/9ZxPHqv1vXB9jTNOs\n6FtK5kQ4/3vw8e9h+xKn05yVrh2jeOuuC7nzkgz+unIPN/zxYz7f3zauKDLGnGBF35LGPOke0vjd\nu9x3z7ZB4aEuHpnQj1e+nUX+wQqueX45/1mX73QsY8wZsKJvSWGR7iESqo/CO1Ogru1exXJlvy7M\nv+8SMpPjuP+NdUx/Z4MdyjGmjWhW0YvIWBHJFZEdIjKtkfl3i8hGEVknIitEpJ/XvOme9XJF5Gpf\nhm8TEvvAuN/A5x/AR//ndJpzktK+Hf+cMpJ7Rvfgn5/s5do/fMSO4jKnYxljmtBk0YtICPACMA7o\nB9ziXeQer6vqQFUdAvwGeMazbj/gZqA/MBZ40fN+wWXoZBhwI7z/JHyx2uk05yQsxMVPxvbltdtH\nsL+8kom//4hZa/OcjmWMOY3m7NGPAHao6i5VrQLeAK71XkBVD3u9jAaOD+N4LfCGqlaq6ufADs/7\nBRcRuOb/3FfjvH0HVHzpdKJzdlnvRObffwmDu8bz47fW86M313O0qsbpWMaYRjSn6FOBvV6v8zzT\nGhCRe0VkJ+49+vvOcN0pIpItItklJSXNzd621A9pXAiz7/P7IY2bo0tcJP/43kjuu6IX73yWx8Tf\nr2Br0eGmVzTGtCqfnYxV1RdUtQfwMPDoGa47Q1WzVDUrMTHRV5H8T+pwuOLnkDMbsmc6ncYnQlzC\ng1f15h93XMDhYzVc+4ePeOOTL9AA2JAZEyiaU/T5QFev12meaafyBnDdWa4b+C6cCj2vhIXTYd9m\np9P4zEU9E5h/3yWcn96Rae9s5P431lFeaYdyjPEHzSn6NUAvEckQkXDcJ1dney8gIr28Xk4Atnt+\nng3cLCIRIpIB9AI+OffYbZjLBde9BO3aw1ttZ0jj5kiMjeCvt4/gx2N6M3dDAdc8v5xN+YecjmVM\n0Guy6FW1BpgKvAfkAG+q6mYReUxEJnkWmyoim0VkHfAgcJtn3c3Am8AWYCFwr6raxdcxiZ4hjbfB\nwq9crdqmuVzC1K/14o0pF3Ksuo7rX/yYv63cbYdyjHGQ+Ns/wKysLM3OznY6Ruv472Ow/H/dJ2kH\n3OB0Gp87cKSKB99cx7LcEsYPTOJX1w8ivl2Y07GMCUgislZVsxqbZ3fGOmn0dOh6gWdI48+dTuNz\nHaPDmXnb+Uwf15dFm/dxze+Xs37vQadjGRN0rOidFBLmHtJYxH19fW2104l8zuUS7rqsB/+660Lq\n6uDGlz7mzys+t0M5xrQiK3qnte8Gk34P+Wvh/cedTtNihp/XgXn3jWJ0n848PncLd/51LQePtq2x\n+o1pq6zo/UG/ayHrDvjoOdjRNoc0bo72UeHM+NZwfnZNPz7YVsz455azds8Bp2MZE/Cs6P3F1U9C\n5/7w7t1QFrgP5xYRbh+Vwdvfv4jQEBc3/WkVL32wk7o6O5RjTEuxovcXYe3cV99UlsO7bXtI4+YY\nlNaeufeN4ur+XXh6wVZuf20NpeWVTscyJiBZ0fuTzn1h3K9h1zL46Fmn07S4uMgwXrh1GI9fN4CP\nd5Yy/vnlrN5V6nQsYwKOFb2/GfZt6H89vP8E7A38m4hFhG+NPI9377mIqPBQbnl5Fb//73Zq7VCO\nMT5jRe9vRGDisxCfBrPugIrguO68f0o8c34wiomDU/jfxdv49szVFJcdczqWMQHBit4fRcbDja9C\nWQHMCYwhjZsjJiKUZ785hF/fMJC1e75k/HMr+GjHfqdjGdPmWdH7q7ThcMXPYMt/YO1fnE7TakSE\nb57fjf/cO4r2UWFM/vNqnlm8zQ7lGHMOrOj92YU/gB5XuAc+27fF6TStqk9SLLOnXsyNw9J4/r/b\nufXlVew7bIdyjDkbVvT+zOWCr78EEXEw67tQddTpRK0qKjyU335jMM/cNJiN+YcY99xyluUWOx3L\nmDbHit7fxXR2D2lckgvvTXc6jSOuH5bG7Kmj6BwbwXdeXcNT83MoKbNr7o1pLiv6tqDH5TDqh+5j\n9ZvfdTqNI3p2juHf917MLSO6MePDXVzw1BL+3yur+NeaLzh0NPAGgzPGl2w8+raithpeHQcl2+Du\nD6FDutOJHLN9Xxmz1xcwZ30Bu0uPEhYiXNY7kYmDU7gyswvREaFORzSm1Z1uPHor+rbkyz3w0iWQ\n0AtuX+ge5jiIqSqb8g8ze30+czcUUnjoGJFhLq7I7MLEQSmM7pNIZFiI0zGNaRVW9IFk87/hrdvg\n4gfgql86ncZv1NUp2Xu+ZM76AuZvLKT0SBWxEaGM6Z/ExMHJXNwzgbAQO1JpApcVfaCZ8wCsfRUm\nvwM9r3A6jd+pqa3j452lzFlfwMLNRZQdq6FjdDjjBiQxcXAKI9I74nKJ0zGN8Skr+kBTXQEvfw2O\nlMDdH0FsF6cT+a3Kmlo+yC1hzoZClmzZR0V1LUlxkUwYlMykwSkMSotHxErftH1W9IGoOAdmXA7d\nRsJNr7mHTTCndbSqhiU5xcxZX8AHuSVU1dbRrWMUEwcnM2lwKn2SYp2OaMxZO+eiF5GxwHNACPCK\nqj590vwHge8BNUAJcLuq7vHMqwU2ehb9QlUnne53WdGfgbV/gTn3AwKJfSAtC9LOd38l9gWXnYg8\nlUMV1by3uYg56wv4eGcptXVK7y4xTBqcwjWDUkhPiHY6ojFn5JyKXkRCgG3AVUAesAa4RVW3eC1z\nObBaVY+KyPeB0ar6Tc+8ckk9M/gAAA+ESURBVFWNaW5YK/oztGcl7FkBe9dA3hqo8DyaLzwGUoed\nKP7ULIhJdDarn9pfXsmCjYXMXl/Amt1fAjAoLZ5Jg1OYMCiZ5Ph2Dic0pmnnWvQXAr9Q1as9r6cD\nqOqvTrH8UOAPqnqx57UVfWtRhQO7IC/bXfp5a2DfJqircc/vkO4p/hHuvf8uAyA03NHI/qbgYAXz\nNrhLf2P+IQBGpHdk4pAUxg9IolNMhMMJjWncuRb9jcBYVf2e5/W3gAtUdeoplv8DUKSqT3he1wDr\ncB/WeVpV/93IOlOAKQDdunUbvmfPnuZ+NtOUqqNQuP5E8eetgbJC97zQSEge0vCQT3yqs3n9yOf7\njzB3fQGz1xewvbicEJdwUY9OTBqcwpj+ScS3C+77GIx/abWiF5HJwFTgMlWt9ExLVdV8EekOvA9c\noao7T/X7bI++FRzK9yr+bCj4DGo9Y8fEpjQs/pQh7ufZBjFVJXdfGbPXFTBnQwF7D1QQHuJidJ8T\nd+O2C7fzIcZZpyv65twrng909Xqd5pl28i+5EngEr5IHUNV8z/ddIrIMGAqcsuhNK4hPdX/1v879\nuqYK9m1seMgnZ7Z7nivUfYjnePGnZUHH7u4nYQUJEaFvUhx9x8bx0NV9WJ93iNnrCpi7oYBFW/YR\nFR7ClZldmDg4hUt7JxARaqVv/Etz9uhDcZ+MvQJ3wa8BblXVzV7LDAVm4d7z3+41vQNwVFUrRSQB\nWAlc630i92S2R+8nyksg36v48z+FqnL3vHYdGxZ/6nCIjHM2rwNq65Q1uw8we30BCzYW8uXRauIi\nQxk7IIlJg1MZ2b0joXY3rmklvri8cjzwLO7LK2eq6pMi8hiQraqzRWQJMBDwHPx1X0YpIhcBfwLq\ncI+U+ayq/vl0v8uK3k/V1ULJ1oaHfEq2emYKdM5seMgnoY97PP0gUV1bx4od+5mzvoBFm/dRXllD\nQkw44we6b8wa1q2D3Y1rWpTdMGVaRsVByF/b8JDPMc/DzCPivnp5Z3QnZ/O2kmPVtSzLLWbO+kKW\n5OyjsqaOlPhIrhmcwqTBKfRPibO7cY3PWdGb1qEKpTsbXuGzbzNorXt+x+4ND/l0GRDwI3CWV9aw\nZMs+5qwv4MPtJVTXKt0Toj2ln0zPznY3rvENK3rjnKojULCuYfmX73PPC42ElKFe5X8+xCU7m7cF\nHTxaxcJNRczZUMDKnaXUKfRNimXSkBQmDkqha8copyOaNsyK3vgPVTiU17D4C9dDbZV7flxaw2P9\nyYMhLNLZzC2guOwY8zcUMmdDIWv3uO/GHdqtPRMHue/G7RIXeJ/ZtCwreuPfaiqhaGPD8j/4hXue\nKwySBjY85NMhPaAu79x74CjzNhYye10BWwoPIwIjMzoxcXAK4wYk0SHa7l42TbOiN21P2T6vyzuz\n3Sd9q4+650W2h7gUiE50Pzw9urN7HJ/oRK+fO7tft7EhHnYUlzN3g/tu3F0lRwh1CZf0SmDcgGQG\ndY2nZ2KMXbJpGmVFb9q+2hooyXEXf9FGKC92fx0pdl/zX32k8fUi4z3l39lrw5DY+EYi3H9GrFRV\nthQeZvb6AuauLyT/YAUA4aEu+ibF0j8ljn4p8QxIiaNvUpzdmWus6E0QqDrifhBLeYmn/Ivdr4+U\nnPj5+Ibh2KHG3yMs+sRfAzGdITrh1BuJyPhWO3ykquwoLmdzwWE2FxzyfD/MoYpqAFwCPRJj6J8S\nR/+U+Prv8VGBfUWTaciK3hhvNZVwZP+JvwbqNwz7G24kyovhaCnQyL+RkAhP+TdyyOjkjUS7jj6/\neUxVyT9YUV/6WzwbgMJDx+qXSW3frkH5D0iNp0tchH9ew6/q/t+lttI9JEdtFWgdhIS7L8ENjXD/\n7AoNqPMzvmRFb8zZqq1xj/HvfZjoSPGp/3o4PiS0NwnxFH9iw78M6v9C8D6vkHBO9xaUllfWl//m\ngkNsKTjM56VHOP7PvFN0OP2ToxmUFMWALhFkdo6ka1wIrrrqk4q20l22x3+u/358eiXUVjcyzet7\nY9OO/47a6obT6qqb+QnFXfihEe7/TiHhJ77qp0U03DjUTwt3n7NpdJ1Tvc9JG5r6ZY7/7LV+aISj\nD/s510HNjAleIaHuQo7p3PSydXXuO4O9DxOVezYA3huJ0p3u7zXHGn+fdh2+esgoMv6k4vUu0xPT\nOtVWcWlNJZceL9CQauo6VlJXfQytqcRVW01IXq37EUK+ICEnSjA0wl18oeFe3z1fUdGnmHfytIgT\n7yfi2Zh4f86qExuKkzc43huP2iqoOHrSeo28j9b56D/E8f8erlNvVJqzoenUA0b90LeZsKI3xndc\nLojq6P5K7HP6ZVXdg8SdfP7gyP6GG4nCde7vVWXuS00blKpXuR7f6wyNdG8UvOa5QsJwnbR8jSuM\nkgqloKyOvMM17D5Yy+6D1ZTVhFBFKLWucLp0iOO8zu1J79yB7skd6ZHUiaioqIa/v60/rrKutpEN\nRiMbh8Y2NN4bldqqxqedauNUUwmVh7+6TlmRFb0xAUMEImLdX516NL28qk+PTYcCyZ6v4Z5pdXXK\n7tIjDQ79fLD7MKWbq4AiRIrI6BRNvwYnfePa9lO3XCHgahfwz1ywojemLWiFE5Aul9A9MYbuiTFM\nHJwCuE/6Fh0+xub8E+X/2RcHmbuhsH69pLjI+tLvn+reAKS2b+efJ32DlBW9MeaURITk+HYkx7fj\nyn5d6qcfPFrFFq89/80Fh1maW0yd56RvfLuwE+Xv2fvvnhhDiA3V7AgremPMGWsfFc5FPRO4qGdC\n/bSKqlpyihpe7vnayj1U1bhPeEaGueib1LD8+yTFEhnWxo/ztwF2eaUxpsVU19axs6S8waGfLQWH\nKat0X4Ya4hJ6dY5pcNy/X0occZF2s9eZsuvojTF+Q1XZe6CCTQWHGtzpW1JW/6hpunWMqt/j75sU\nR2ZyLF07RNlTuk7DrqM3xvgNEaFbpyi6dYpi/MATzx8oLjvmOexzYs9/4eai+pu9osJDPMXvLv/j\n322oh6bZHr0xxm8draph275ythYeZmtRGVuLDpNTWFY/zg9ASnykewOQ7C7/zOQ4MhKiCQuyUT5t\nj94Y0yZFhYcypGt7hnRtXz9NVdl3uJKcosNsLSwjt8i9EVi+fT81nst+wkNc9OgcQ2ZSLH2TY+mT\nFEdmUiyJsX461k8Ls6I3xrQpIkJSfCRJ8ZFc3ufE0BRVNe4Tv7lFZfUbgY927uedz/Lrl+kYHd7w\n0E9yLL06xwb8MM/NKnoRGQs8B4QAr6jq0yfNfxD4HlADlAC3q+oez7zbgEc9iz6hqq/5KLsxxtQL\nD3WRmRxHZnIc15FaP/3LI1X1h322FpaxdV8Zr3+yh2PV7ss+XQLpCdENNgCZye6bvgLl5G+Tx+hF\nJATYBlyFeyikNcAtqrrFa5nLgdWqelREvg+MVtVvikhHIBvIwj3W61pguKp+earfZ8fojTEtrbZO\n+eLAUbYWHian6MThnz2lR+uXiYkIpXeXGPomx3kOAbmvAvLXSz/P9Rj9CGCHqu7yvNkbwLVAfdGr\n6lKv5VcBkz0/Xw0sVtUDnnUXA2OBf57phzDGGF8JcQkZCdFkJEQzzuvKnyOVNeTuKyO3qKx+IzB3\nfQGvrz4x/HRq+3b1h32O/wWQkRDt1494bE7RpwJ7vV7nARecZvk7gAWnWTf15BVEZAowBaBbt27N\niGSMMb4XHRHKsG4dGNatQ/204+P9bC0s8zoBXMYH20pOnPwNddGrc0yDY/99k+JIjPWPAd98ejJW\nRCbjPkxz2Zmsp6ozgBngPnTjy0zGGHMuvMf7ubzviZO/lTW17Cw+4j72X1TmufKnhLc/PTHYf0JM\nOH2T4uqv/89MjqNn55hWH/ahOUWfD3T1ep3mmdaAiFwJPAJcpqqVXuuOPmndZWcT1Bhj/ElEaAj9\nPEM2eCstr3Qf+jl+AriojL+v2kNlzYmTvxkJ0SeO/Xs2BGkdWm7Ez+acjA3FfTL2CtzFvQa4VVU3\ney0zFJgFjFXV7V7TO+I+ATvMM+lT3CdjD5zq99nJWGNMoKn1jPXvfex/a9Fh9h6oqF8mNiKUy/ok\n8odbh53mnU7tnE7GqmqNiEwF3sN9eeVMVd0sIo8B2ao6G/gtEAO85dkifaGqk1T1gIg8jnvjAPDY\n6UreGGMCUYhL6JEYQ4/EmAbDPpRX1nj2/t3H/uPatcytTTYEgjHGBIDT7dH77/VAxhhjfMKK3hhj\nApwVvTHGBDgremOMCXBW9MYYE+Cs6I0xJsBZ0RtjTICzojfGmADndzdMiUgJsOcc3iIB2O+jOG1F\nsH3mYPu8YJ85WJzLZz5PVRMbm+F3RX+uRCT7VHeHBapg+8zB9nnBPnOwaKnPbIdujDEmwFnRG2NM\ngAvEop/hdAAHBNtnDrbPC/aZg0WLfOaAO0ZvjDGmoUDcozfGGOPFit4YYwJcwBS9iIwVkVwR2SEi\n05zO09JEZKaIFIvIJqeztBYR6SoiS0Vki4hsFpH7nc7U0kQkUkQ+EZH1ns/8S6cztQYRCRGRz0Rk\nrtNZWouI7BaRjSKyTkR8+vSlgDhGLyIhuJ9rexWQh/vRhbeo6hZHg7UgEbkUKAf+qqoDnM7TGkQk\nGUhW1U9FJBb384ivC/D/nQWIVtVyEQkDVgD3q+oqh6O1KBF5EMgC4lT1GqfztAYR2Q1kqarPbxIL\nlD36EcAOVd2lqlXAG8C1DmdqUar6IRBUz99V1UJV/dTzcxmQA6Q6m6plqVu552WY56vt752dhoik\nAROAV5zOEigCpehTgb1er/MI8AIIdiKSDgwFVjubpOV5DmOsA4qBxaoa6J/5WeAnQJ3TQVqZAotE\nZK2ITPHlGwdK0ZsgIiIxwNvAA6p62Ok8LU1Va1V1CJAGjBCRgD1UJyLXAMWqutbpLA4YparDgHHA\nvZ7Dsz4RKEWfD3T1ep3mmWYCjOc49dvAP1T1HafztCZVPQgsBcY6naUFXQxM8hyvfgP4moj83dlI\nrUNV8z3fi4F3cR+S9olAKfo1QC8RyRCRcOBmYLbDmYyPeU5M/hnIUdVnnM7TGkQkUUTae35uh/uC\ng63Opmo5qjpdVdNUNR33v+P3VXWyw7FanIhEey4wQESigTGAz66oC4iiV9UaYCrwHu4TdG+q6mZn\nU7UsEfknsBLoIyJ5InKH05lawcXAt3Dv5a3zfI13OlQLSwaWisgG3Ds0i1U1aC45DCJdgBUish74\nBJinqgt99eYBcXmlMcaYUwuIPXpjjDGnZkVvjDEBzoreGGMCnBW9McYEOCt6Y4wJcFb0xhgT4Kzo\njTEmwP1/tAslB+Z9LwYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}